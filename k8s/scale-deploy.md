# Claude

脚本功能总结

这个脚本用于自动化管理 Kubernetes 部署（Deployment）在节点间的分布，通过检查每个 Deployment 的 Pod 分布情况，对副本数量进行调整，并验证 Deployment 的状态。以下是脚本实现的主要功能：
	1.	收集运行中 Pod 的 Deployment 信息：
	•	脚本通过 kubectl 获取所有运行中的 Pod 信息。
	•	使用 jq 提取每个 Pod 的所属命名空间、Deployment 名称，以及 Pod 所在节点的分布情况。
	2.	分析 Deployment 分布状态：
	•	对每个 Deployment 的 Pod 信息进行分组。
	•	计算每个 Deployment 当前的 Pod 数量和分布的节点数量。
	3.	调整 Deployment 副本数量：
	•	如果某个 Deployment 的 Pod 全部集中在单个节点（节点数量 < 2），脚本会尝试通过增加副本数量来分散 Pod 的分布，以提高高可用性。
	•	如果某个 Deployment 的 Pod 已经分布在多个节点上，则无需调整。
	4.	检查 Deployment 的 Rollout 状态：
	•	对每个 Deployment 执行 kubectl rollout status，确认 Deployment 的更新和滚动发布是否完成。
	•	在日志文件中记录每次检查的结果。
	5.	日志记录：
	•	将所有操作（如 Pod 分布检查、Deployment 副本调整和 Rollout 状态检查）的输出记录到日志文件 deployment_scale.log 中，以便后续排查和分析。

脚本的用途

这个脚本适用于 Kubernetes 集群的以下场景：
	•	高可用性优化：
确保 Deployment 的 Pod 分布在不同节点上，防止单点故障。
	•	资源监控与调度：
自动检查 Pod 的分布状态，动态调整 Deployment 的副本数量。
	•	自动化运维：
减少手动检查和调整 Deployment 的操作，提高运维效率。

总之，这个脚本为 Kubernetes 集群中的 Deployment 提供了一个高可用性监控和自动化调整的解决方案。



我将根据您提供的新方法 `get_deployments_on_nodes()` 重构脚本。以下是优化后的脚本：

```bash
#!/bin/bash
# 设定日志文件
LOG_FILE="deployment_scale.log"

# 使用新的函数获取需要扩展的 Deployments
scale_deployments() {
    local deployments_to_scale
    deployments_to_scale=$(get_deployments_on_nodes)

    # 使用 jq 解析并遍历需要扩展的 Deployments
    echo "$deployments_to_scale" | jq -c '.[]' | while read -r deployment; do
        local namespace=$(echo "$deployment" | jq -r '.namespace')
        local deployment_name=$(echo "$deployment" | jq -r '.deployment')
        local current_nodes=$(echo "$deployment" | jq -r '.nodes')
        local current_pods=$(echo "$deployment" | jq -r '.pods')

        # 记录日志
        echo "Deployment $deployment_name in namespace $namespace has $current_pods pods on $current_nodes nodes" | tee -a "$LOG_FILE"

        # 获取当前 Deployment 的副本数
        local current_replicas=$(kubectl get deployment "$deployment_name" -n "$namespace" -o jsonpath='{.spec.replicas}')
        
        # 计算新的副本数（确保至少跨越2个节点）
        local new_replicas=$((current_replicas * 2))

        # 扩展 Deployment
        kubectl scale deployment "$deployment_name" --replicas="$new_replicas" -n "$namespace" | tee -a "$LOG_FILE"
        echo "Scaled deployment $deployment_name in namespace $namespace to $new_replicas replicas" | tee -a "$LOG_FILE"

        # 检查扩展后的 Deployment 状态
        if ! kubectl rollout status deployment "$deployment_name" -n "$namespace" --timeout=5m; then
            echo "Timeout waiting for deployment $deployment_name to finish in namespace $namespace" | tee -a "$LOG_FILE"
        fi
    done
}

# 主函数定义
get_deployments_on_nodes() {
    local pods=$(kubectl get pods --all-namespaces -o json)
    
    echo "$pods" | jq -r '.items[] | 
    select(.status.phase == "Running") | 
    select(.metadata.namespace | startswith("kube") | not) | 
    select(.metadata.namespace | startswith("pm") | not) | 
    select(.metadata.namespace == "aibang-core") | 
    select(.metadata.namespace == "scope") | 
    select(.metadata.namespace == "aibang-saas") | 
    select(.metadata.namespace == "opentelemetry-demo") | 
    select(.metadata.namespace | endswith("-kd") | not) 
    | group_by(.metadata.namespace, .metadata.ownerReferences[0].name | sub("[-a-z0-9]+$"; "")) 
    | map({
        namespace: .[0].metadata.namespace,
        deployment: .[0].metadata.ownerReferences[0].name | sub("[-a-z0-9]+$"; ""),
        nodes: (map(.spec.nodeName) | unique | length),
        pods: (map(.metadata.name) | unique | length)
    })
    | map(select(.pods >= 2 and .nodes < 2))'
}

# 执行扩展
scale_deployments
```

主要优化和变更包括：

1. 使用新的 `get_deployments_on_nodes()` 函数来获取需要扩展的 Deployment

2. 新增 `scale_deployments()` 函数来处理 Deployment 扩展逻辑

3. 移除了复杂的关联数组和多重循环，改用更简洁的 jq 和管道处理

4. 扩展策略改为将副本数加倍，确保至少分布在两个节点上

5. 使用 `kubectl rollout status` 检查 Deployment 状态，超时时间设置为 5 分钟

6. 保留了日志记录功能，并简化了日志输出

7. 命名空间选择逻辑保持不变

这个新版本的脚本更加简洁、易读，并且使用了更现代的 Kubernetes 操作方式。它将自动检测并扩展那些 Pod 数量大于等于 2 但运行在少于 2 个节点上的 Deployment。​​​​​​​​​​​​​​​​


# ChatGPT 

下面是优化后的脚本，整合了整理的方法 get_deployments_on_nodes 并替换了原脚本的相关逻辑。此脚本更加模块化和清晰：

#!/bin/bash
# 设定日志文件
LOG_FILE="deployment_scale.log"

# 定义方法：获取每个 Deployment 的节点和 Pod 信息
get_deployments_on_nodes() {
    local pods=$(kubectl get pods --all-namespaces -o json)
    echo "$pods" | jq -r '
    .items[] | 
    select(.status.phase == "Running") | 
    select(.metadata.namespace | startswith("kube") | not) | 
    select(.metadata.namespace | startswith("pm") | not) | 
    select(.metadata.namespace == "aibang-core") | 
    select(.metadata.namespace == "scope") | 
    select(.metadata.namespace == "aibang-saas") | 
    select(.metadata.namespace == "opentelemetry-demo") | 
    select(.metadata.namespace | endswith("-kd") | not) | 
    {
        namespace: .metadata.namespace,
        deployment: (.metadata.ownerReferences[] | select(.kind=="ReplicaSet") | .name | sub("[-0-9]+$"; "")),
        node: .spec.nodeName
    }' | jq -s '
    group_by(.namespace + .deployment) | 
    map({
        namespace: .[0].namespace,
        deployment: .[0].deployment,
        nodes: (map(.node) | unique | length),
        pods: length
    })'
}

# 检查 Deployment 并调整副本数
scale_deployments() {
    local deployments_info=$(get_deployments_on_nodes)
    
    echo "$deployments_info" | jq -c '.[]' | while read -r deployment; do
        namespace=$(echo "$deployment" | jq -r '.namespace')
        deployment_name=$(echo "$deployment" | jq -r '.deployment')
        node_count=$(echo "$deployment" | jq -r '.nodes')
        pod_count=$(echo "$deployment" | jq -r '.pods')

        echo "Checking deployment $deployment_name in namespace $namespace: $pod_count pods on $node_count nodes" | tee -a "$LOG_FILE"

        if [[ $node_count -lt 1 ]]; then
            echo "Scaling deployment $deployment_name in namespace $namespace to distribute Pods" | tee -a "$LOG_FILE"
            kubectl scale deployment "$deployment_name" --replicas=$((pod_count + 1)) --namespace "$namespace" | tee -a "$LOG_FILE"
        elif [[ $node_count -gt 1 ]]; then
            echo "Deployment $deployment_name in namespace $namespace is already distributed across multiple nodes" | tee -a "$LOG_FILE"
        fi
    done
}

# 检查每个 Deployment 的 Rollout 状态
check_rollout_status() {
    local deployments_info=$(get_deployments_on_nodes)
    
    echo "$deployments_info" | jq -c '.[]' | while read -r deployment; do
        namespace=$(echo "$deployment" | jq -r '.namespace')
        deployment_name=$(echo "$deployment" | jq -r '.deployment')

        echo "Checking rollout status for deployment $deployment_name in namespace $namespace" | tee -a "$LOG_FILE"
        kubectl rollout status deployment "$deployment_name" --namespace "$namespace" | tee -a "$LOG_FILE"
    done
}

# 主流程
scale_deployments
check_rollout_status

优化内容说明：
	1.	模块化设计：
	•	将原脚本中的逻辑提取为两个函数：get_deployments_on_nodes 和 scale_deployments，实现职责分离。
	•	提供更清晰的结构，便于维护和扩展。
	2.	精简逻辑：
	•	利用 jq 的强大功能简化 JSON 数据处理过程，避免了 awk 等多步骤操作。
	•	jq 将 JSON 数据分组并提取所需字段，直接生成目标信息。
	3.	改进可读性：
	•	使用 jq -c 输出紧凑的 JSON 对象便于逐行处理。
	•	明确变量命名，易于理解。
	4.	动态扩展副本数：
	•	自动计算当前 Pod 数量，根据需求调整副本数，确保副本的合理分布。
	5.	日志记录：
	•	所有关键操作均追加到日志文件中，便于后续审查。

运行优化后的脚本时，确保环境中已安装 jq 并正确配置 kubectl。




好的，我帮你分析一下这个脚本，并提出一些优化建议：
脚本总结：
 * 功能: 自动化扩展 Kubernetes 集群中指定命名空间下的 Deployment，确保每个 Deployment 至少运行在两个节点上。
 * 流程:
   * 定义 get_deployments_on_nodes 函数，获取满足条件的 Deployment 信息（运行中的 Pod、命名空间、Deployment 名称、节点数、Pod 数）。
   * scale_deployments 函数调用 get_deployments_on_nodes 获取需要扩展的 Deployment 列表。
   * 遍历每个 Deployment，计算新的副本数，并使用 kubectl scale 命令进行扩展。
   * 监控 Deployment 的扩展状态，确保其顺利完成。
优化建议：
 * 命名空间筛选:
   * 可读性: 可以将命名空间的筛选条件提取为一个数组，提高代码可读性。
   * 灵活性: 可以通过配置文件或环境变量来配置需要筛选的命名空间，增加脚本的灵活性。
 * 错误处理:
   * 异常捕获: 可以添加异常捕获机制，例如使用 try-catch 块，以便在脚本执行过程中出现错误时能够及时发现并记录。
   * 错误通知: 可以通过发送邮件、短信等方式通知管理员，以便及时处理问题。
 * 日志记录:
   * 详细程度: 可以增加日志记录的详细程度，例如记录每个 Deployment 的扩展前后的副本数、节点数等信息。
   * 格式化: 可以使用日志格式化工具（如 logfmt）来生成结构化的日志，方便后续分析。
 * 性能优化:
   * 并发扩展: 可以考虑并行扩展多个 Deployment，以提高脚本的执行效率。
   * 缓存: 可以缓存 get_deployments_on_nodes 函数的查询结果，减少重复查询。
 * 参数化:
   * 副本数倍数: 可以将副本数的倍数作为一个参数，以便灵活调整扩展比例。
   * 超时时间: 可以将超时时间作为一个参数，以便根据不同的 Deployment 调整超时设置。
优化后示例代码：
#!/bin/bash
# ... (其他部分保持不变)

# 定义需要筛选的命名空间
namespaces=("aibang-core" "scope" "aibang-saas" "opentelemetry-demo")

# ... (其他部分保持不变)

# 主函数定义
get_deployments_on_nodes() {
    # ... (其他部分保持不变)
    | map(select(.metadata.namespace | in (${namespaces[*]})) | ...)
}

# 执行扩展
scale_deployments

其他注意事项：
 * 资源限制: 在大规模集群中，需要注意脚本对集群资源的影响，避免过多的并发请求导致集群不稳定。
 * 安全考虑: 如果脚本涉及到敏感信息（如 API Token），需要妥善保管，避免泄露。
 * 可维护性: 随着脚本功能的不断扩展，需要保持代码的整洁和可维护性，以便后续的修改和维护。
总结：
这个脚本提供了一个很好的基础，可以通过上述优化建议进一步完善。在实际应用中，可以根据具体的业务需求和环境特点进行调整和扩展。
希望这个分析对你有帮助！





